#!/usr/bin/env python
# -*- coding: utf-8 -*-

import os
import json
import time
import asyncio
import aiohttp
from pathlib import Path
from typing import Dict, List, Any, Optional, Set
import argparse
from loguru import logger
from tqdm import tqdm
import pickle

def load_env():
    """–ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è –∏–∑ .env —Ñ–∞–π–ª–∞"""
    env_file = Path('.env')
    if env_file.exists():
        logger.info("üìÑ –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è –∏–∑ .env —Ñ–∞–π–ª–∞...")
        with open(env_file, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if line and not line.startswith('#') and '=' in line:
                    key, value = line.split('=', 1)
                    value = value.strip().strip('"').strip("'")
                    os.environ[key.strip()] = value
        logger.success("‚úÖ –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –∑–∞–≥—Ä—É–∂–µ–Ω—ã")
    else:
        logger.warning("‚ö†Ô∏è  –§–∞–π–ª .env –Ω–µ –Ω–∞–π–¥–µ–Ω")

# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
load_env()

class AsyncLegalDocumentProcessor:
    def __init__(self, api_key: str, model: str = "gpt-4o-mini", max_concurrent: int = 5):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–≥–æ –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
        
        Args:
            api_key: OpenAI API –∫–ª—é—á
            model: –ú–æ–¥–µ–ª—å –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
            max_concurrent: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
        """
        self.api_key = api_key
        self.model = model
        self.max_concurrent = max_concurrent
        self.processed_count = 0
        self.max_documents = 50000
        self.processed_files: Set[str] = set()
        self.progress_file = "processing_progress.pkl"
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–µ–∑ –∑–∞–≥—Ä—É–∑–∫–∏ —Å—Ç–∞—Ä–æ–≥–æ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
        logger.info("üîÑ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–≥–æ –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞")
        
    def load_progress(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
        if os.path.exists(self.progress_file):
            try:
                with open(self.progress_file, 'rb') as f:
                    self.processed_files = pickle.load(f)
                logger.info(f"üìä –ó–∞–≥—Ä—É–∂–µ–Ω –ø—Ä–æ–≥—Ä–µ—Å—Å: {len(self.processed_files)} —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –ø—Ä–æ–≥—Ä–µ—Å—Å: {e}")
    
    def save_progress(self):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
        try:
            with open(self.progress_file, 'wb') as f:
                pickle.dump(self.processed_files, f)
            logger.info(f"üíæ –ü—Ä–æ–≥—Ä–µ—Å—Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {len(self.processed_files)} —Ñ–∞–π–ª–æ–≤")
        except Exception as e:
            logger.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –ø—Ä–æ–≥—Ä–µ—Å—Å: {e}")
    
    def create_analysis_prompt(self, text: str, filename: str) -> str:
        """
        –°–æ–∑–¥–∞–µ—Ç –¥–µ—Ç–∞–ª—å–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Å—É–¥–µ–±–Ω–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞
        
        Args:
            text: –¢–µ–∫—Å—Ç –¥–æ–∫—É–º–µ–Ω—Ç–∞
            filename: –ò–º—è —Ñ–∞–π–ª–∞
            
        Returns:
            –ü—Ä–æ–º–ø—Ç –¥–ª—è OpenAI
        """
        return f"""–¢—ã - —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∞–Ω–∞–ª–∏–∑—É —Å—É–¥–µ–±–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —Å 20-–ª–µ—Ç–Ω–∏–º –æ–ø—ã—Ç–æ–º —Ä–∞–±–æ—Ç—ã –≤ –í–µ—Ä—Ö–æ–≤–Ω–æ–º –°—É–¥–µ –†–§. –¢–≤–æ—è –∑–∞–¥–∞—á–∞ - –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ —Ç–æ—á–Ω–æ –∏ –¥–µ—Ç–∞–ª—å–Ω–æ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Å—É–¥–µ–±–Ω—ã–π –¥–æ–∫—É–º–µ–Ω—Ç –∏ –∏–∑–≤–ª–µ—á—å —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –Ω–µ–π—Ä–æ—Å–µ—Ç–∏.

–¢–ï–ö–°–¢ –î–û–ö–£–ú–ï–ù–¢–ê:
{text}

–í–ê–ñ–ù–û: –ê–Ω–∞–ª–∏–∑–∏—Ä—É–π –¥–æ–∫—É–º–µ–Ω—Ç –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –≤–Ω–∏–º–∞—Ç–µ–ª—å–Ω–æ. –ö–∞–∂–¥–∞—è –¥–µ—Ç–∞–ª—å –∏–º–µ–µ—Ç –∑–Ω–∞—á–µ–Ω–∏–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏.

–ò–ù–°–¢–†–£–ö–¶–ò–ò –ü–û –ê–ù–ê–õ–ò–ó–£:

1. –û–ü–†–ï–î–ï–õ–ò –¢–ò–ü –î–û–ö–£–ú–ï–ù–¢–ê:
   - –†–µ—à–µ–Ω–∏–µ —Å—É–¥–∞
   - –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å—É–¥–∞  
   - –ü–æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—É–¥–∞
   - –ü—Ä–∏–≥–æ–≤–æ—Ä —Å—É–¥–∞
   - –î—Ä—É–≥–æ–µ (—É–∫–∞–∑–∞—Ç—å —Ç–æ—á–Ω–æ)

2. –ò–ó–í–õ–ï–ö–ò –û–°–ù–û–í–ù–£–Æ –ò–ù–§–û–†–ú–ê–¶–ò–Æ:
   - –ù–∞–∑–≤–∞–Ω–∏–µ —Å—É–¥–∞ (–ø–æ–ª–Ω–æ–µ –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ)
   - –ù–æ–º–µ—Ä –¥–µ–ª–∞ (—Ç–æ—á–Ω–æ –∫–∞–∫ —É–∫–∞–∑–∞–Ω–æ)
   - –î–∞—Ç–∞ –≤—ã–Ω–µ—Å–µ–Ω–∏—è (–≤ —Ñ–æ—Ä–º–∞—Ç–µ –î–î.–ú–ú.–ì–ì–ì–ì)
   - –°—É–¥—å—è (–ø–æ–ª–Ω–æ–µ –§–ò–û)
   - –°—Ç–æ—Ä–æ–Ω—ã –¥–µ–ª–∞ (–∏—Å—Ç–µ—Ü/–∑–∞—è–≤–∏—Ç–µ–ª—å, –æ—Ç–≤–µ—Ç—á–∏–∫/–æ–±–≤–∏–Ω—è–µ–º—ã–π —Å –ø–æ–ª–Ω—ã–º–∏ –§–ò–û)

3. –†–ê–ó–î–ï–õ–ò –ù–ê –°–ï–ö–¶–ò–ò (–ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û):
   - –£–°–¢–ê–ù–û–í–û–ß–ù–ê–Ø –ß–ê–°–¢–¨: —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –æ–±—Å—Ç–æ—è—Ç–µ–ª—å—Å—Ç–≤–∞ –¥–µ–ª–∞, –¥–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤–∞, –ø–æ–∫–∞–∑–∞–Ω–∏—è —Å—Ç–æ—Ä–æ–Ω
   - –ú–û–¢–ò–í–ò–†–û–í–û–ß–ù–ê–Ø –ß–ê–°–¢–¨: –ø—Ä–∞–≤–æ–≤–∞—è –æ—Ü–µ–Ω–∫–∞, –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ —Ä–µ—à–µ–Ω–∏—è, —Å—Å—ã–ª–∫–∏ –Ω–∞ –∑–∞–∫–æ–Ω—ã
   - –†–ï–ó–û–õ–Æ–¢–ò–í–ù–ê–Ø –ß–ê–°–¢–¨: –≤—ã–≤–æ–¥—ã –∏ —Ä–µ—à–µ–Ω–∏—è —Å—É–¥–∞

4. –û–ü–†–ï–î–ï–õ–ò –ü–†–ï–î–ú–ï–¢ –°–ü–û–†–ê:
   - –ö—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ —Å—É—Ç–∏ —Å–ø–æ—Ä–∞ (1-2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è)
   - –û—Å–Ω–æ–≤–Ω—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è —Å—Ç–æ—Ä–æ–Ω (–∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ)
   - –ü—Ä–µ–¥–º–µ—Ç–Ω–∞—è –æ–±–ª–∞—Å—Ç—å –ø—Ä–∞–≤–∞ (–≥—Ä–∞–∂–¥–∞–Ω—Å–∫–æ–µ, —É–≥–æ–ª–æ–≤–Ω–æ–µ, –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–∏–≤–Ω–æ–µ, –Ω–∞–ª–æ–≥–æ–≤–æ–µ, —Ç—Ä—É–¥–æ–≤–æ–µ, –∞—Ä–±–∏—Ç—Ä–∞–∂–Ω–æ–µ)

5. –í–´–î–ï–õ–ò –ö–õ–Æ–ß–ï–í–´–ï –§–ê–ö–¢–´:
   - –û—Å–Ω–æ–≤–Ω—ã–µ –æ–±—Å—Ç–æ—è—Ç–µ–ª—å—Å—Ç–≤–∞ –¥–µ–ª–∞ (—Ö—Ä–æ–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏)
   - –í–∞–∂–Ω—ã–µ –¥–∞—Ç—ã –∏ —Å–æ–±—ã—Ç–∏—è
   - –ü—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–µ –¥–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤–∞
   - –ö–ª—é—á–µ–≤—ã–µ –∞—Ä–≥—É–º–µ–Ω—Ç—ã —Å—Ç–æ—Ä–æ–Ω

6. –ò–ó–í–õ–ï–ö–ò –ü–†–ê–í–û–í–´–ï –ù–û–†–ú–´:
   - –ü—Ä–∏–º–µ–Ω–µ–Ω–Ω—ã–µ —Å—Ç–∞—Ç—å–∏ –∑–∞–∫–æ–Ω–æ–≤ (—Å –Ω–æ–º–µ—Ä–∞–º–∏)
   - –°—Å—ã–ª–∫–∏ –Ω–∞ –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–µ –∞–∫—Ç—ã
   - –ü—Ä–∞–≤–æ–≤—ã–µ –ø—Ä–∏–Ω—Ü–∏–ø—ã
   - –°—É–¥–µ–±–Ω–∞—è –ø—Ä–∞–∫—Ç–∏–∫–∞ (–µ—Å–ª–∏ —É–ø–æ–º–∏–Ω–∞–µ—Ç—Å—è)

7. –û–ü–†–ï–î–ï–õ–ò –†–ï–ó–£–õ–¨–¢–ê–¢:
   - –†–µ—à–µ–Ω–∏–µ —Å—É–¥–∞ (–∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ)
   - –û–±–∂–∞–ª–æ–≤–∞–Ω–∏–µ (–µ—Å–ª–∏ —É–ø–æ–º–∏–Ω–∞–µ—Ç—Å—è)
   - –ò—Å–ø–æ–ª–Ω–µ–Ω–∏–µ —Ä–µ—à–µ–Ω–∏—è (–µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω–æ)

8. –ö–ê–ß–ï–°–¢–í–û –ê–ù–ê–õ–ò–ó–ê:
   - –û—Ü–µ–Ω–∫–∞ –ø–æ–ª–Ω–æ—Ç—ã –∏–∑–≤–ª–µ—á–µ–Ω–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
   - –£—Ä–æ–≤–µ–Ω—å —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –≤ –∞–Ω–∞–ª–∏–∑–µ
   - –û—Å–æ–±—ã–µ –∑–∞–º–µ—á–∞–Ω–∏—è

–í–ï–†–ù–ò –û–¢–í–ï–¢ –°–¢–†–û–ì–û –í –°–õ–ï–î–£–Æ–©–ï–ú JSON –§–û–†–ú–ê–¢–ï (–±–µ–∑ –ª–∏—à–Ω–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤):

{{
    "document_info": {{
        "filename": "{filename}",
        "document_type": "—Ç–∏–ø –¥–æ–∫—É–º–µ–Ω—Ç–∞",
        "court_name": "–Ω–∞–∑–≤–∞–Ω–∏–µ —Å—É–¥–∞",
        "case_number": "–Ω–æ–º–µ—Ä –¥–µ–ª–∞",
        "decision_date": "–¥–∞—Ç–∞ –≤—ã–Ω–µ—Å–µ–Ω–∏—è",
        "judge": "–§–ò–û —Å—É–¥—å–∏",
        "parties": {{
            "plaintiff": "–∏—Å—Ç–µ—Ü/–∑–∞—è–≤–∏—Ç–µ–ª—å",
            "defendant": "–æ—Ç–≤–µ—Ç—á–∏–∫/–æ–±–≤–∏–Ω—è–µ–º—ã–π"
        }}
    }},
    "sections": {{
        "factual_part": "—É—Å—Ç–∞–Ω–æ–≤–æ—á–Ω–∞—è —á–∞—Å—Ç—å (—Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –æ–±—Å—Ç–æ—è—Ç–µ–ª—å—Å—Ç–≤–∞)",
        "reasoning_part": "–º–æ—Ç–∏–≤–∏—Ä–æ–≤–æ—á–Ω–∞—è —á–∞—Å—Ç—å (–ø—Ä–∞–≤–æ–≤–∞—è –æ—Ü–µ–Ω–∫–∞)",
        "operative_part": "—Ä–µ–∑–æ–ª—é—Ç–∏–≤–Ω–∞—è —á–∞—Å—Ç—å (—Ä–µ—à–µ–Ω–∏–µ —Å—É–¥–∞)"
    }},
    "case_details": {{
        "dispute_subject": "–ø—Ä–µ–¥–º–µ—Ç —Å–ø–æ—Ä–∞",
        "parties_claims": "—Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è —Å—Ç–æ—Ä–æ–Ω",
        "legal_area": "–æ–±–ª–∞—Å—Ç—å –ø—Ä–∞–≤–∞"
    }},
    "key_facts": [
        "—Ñ–∞–∫—Ç 1",
        "—Ñ–∞–∫—Ç 2",
        "—Ñ–∞–∫—Ç 3"
    ],
    "legal_norms": [
        "—Å—Ç–∞—Ç—å—è –∑–∞–∫–æ–Ω–∞ 1",
        "—Å—Ç–∞—Ç—å—è –∑–∞–∫–æ–Ω–∞ 2"
    ],
    "court_decision": "—Ä–µ—à–µ–Ω–∏–µ —Å—É–¥–∞",
    "analysis_quality": {{
        "completeness": "–æ—Ü–µ–Ω–∫–∞ –ø–æ–ª–Ω–æ—Ç—ã",
        "confidence": "—É—Ä–æ–≤–µ–Ω—å —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏",
        "notes": "–æ—Å–æ–±—ã–µ –∑–∞–º–µ—á–∞–Ω–∏—è"
    }}
}}"""

    async def analyze_document_async(self, session: aiohttp.ClientSession, text: str, filename: str, proxy_settings: str = None) -> Optional[Dict[str, Any]]:
        """
        –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞ —Å –ø–æ–º–æ—â—å—é OpenAI API
        
        Args:
            session: aiohttp —Å–µ—Å—Å–∏—è
            text: –¢–µ–∫—Å—Ç –¥–æ–∫—É–º–µ–Ω—Ç–∞
            filename: –ò–º—è —Ñ–∞–π–ª–∞
            
        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞ –∏–ª–∏ None –ø—Ä–∏ –æ—à–∏–±–∫–µ
        """
        try:
            prompt = self.create_analysis_prompt(text, filename)
            
            headers = {
                "Authorization": f"Bearer {self.api_key}",
                "Content-Type": "application/json"
            }
            
            data = {
                "model": self.model,
                "messages": [{"role": "user", "content": prompt}],
                "max_tokens": 4000,
                "temperature": 0.1
            }
            
            # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–æ–∫—Å–∏ –≤ –∑–∞–ø—Ä–æ—Å
            request_kwargs = {
                "headers": headers,
                "json": data,
                "timeout": aiohttp.ClientTimeout(total=120)
            }
            
            # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–æ–∫—Å–∏ –µ—Å–ª–∏ –Ω–∞—Å—Ç—Ä–æ–µ–Ω
            if proxy_settings:
                request_kwargs["proxy"] = proxy_settings
            
            async with session.post(
                "https://api.openai.com/v1/chat/completions",
                **request_kwargs
            ) as response:
                if response.status == 200:
                    result = await response.json()
                    content = result["choices"][0]["message"]["content"]
                    
                    # –ü–∞—Ä—Å–∏–º JSON –æ—Ç–≤–µ—Ç
                    try:
                        analysis_result = json.loads(content)
                        analysis_result["processing_info"] = {
                            "processed_at": time.strftime("%Y-%m-%d %H:%M:%S"),
                            "model_used": self.model,
                            "filename": filename
                        }
                        return analysis_result
                    except json.JSONDecodeError as e:
                        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON –¥–ª—è {filename}: {e}")
                        logger.error(f"üìÑ –ü–æ–ª—É—á–µ–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç: {content[:200]}...")
                        return None
                else:
                    error_text = await response.text()
                    logger.error(f"‚ùå API –æ—à–∏–±–∫–∞ –¥–ª—è {filename}: {response.status} - {error_text}")
                    return None
                    
        except asyncio.TimeoutError:
            logger.error(f"‚è∞ –¢–∞–π–º–∞—É—Ç –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ {filename}")
            return None
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ {filename}: {e}")
            return None

    def save_result(self, result: Dict[str, Any], output_dir: str, filename: str) -> None:
        """
        –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –∞–Ω–∞–ª–∏–∑–∞
        
        Args:
            result: –†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞
            output_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
            filename: –ò–º—è —Ñ–∞–π–ª–∞
        """
        try:
            os.makedirs(output_dir, exist_ok=True)
            
            # –°–æ–∑–¥–∞–µ–º –∏–º—è –≤—ã—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
            base_name = Path(filename).stem
            output_file = os.path.join(output_dir, f"{base_name}_analyzed.json")
            
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(result, f, ensure_ascii=False, indent=2)
            
            logger.info(f"‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {output_file}")
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –¥–ª—è {filename}: {e}")

    async def process_text_file_async(self, session: aiohttp.ClientSession, input_file: str, output_dir: str) -> bool:
        """
        –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ —Ñ–∞–π–ª–∞
        
        Args:
            session: aiohttp —Å–µ—Å—Å–∏—è
            input_file: –ü—É—Ç—å –∫ –≤—Ö–æ–¥–Ω–æ–º—É —Ñ–∞–π–ª—É
            output_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
            
        Returns:
            True –µ—Å–ª–∏ —É—Å–ø–µ—à–Ω–æ, False –∏–Ω–∞—á–µ
        """
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω –ª–∏ —É–∂–µ —Ñ–∞–π–ª
            if input_file in self.processed_files:
                logger.info(f"‚è≠Ô∏è  –§–∞–π–ª —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º: {input_file}")
                return True
            
            # –ß–∏—Ç–∞–µ–º —Ñ–∞–π–ª
            with open(input_file, 'r', encoding='utf-8') as f:
                text = f.read()
            
            filename = os.path.basename(input_file)
            logger.info(f"üìÑ –û–±—Ä–∞–±–æ—Ç–∫–∞: {filename}")
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –¥–æ–∫—É–º–µ–Ω—Ç
            result = await self.analyze_document_async(session, text, filename)
            
            if result:
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                self.save_result(result, output_dir, filename)
                
                # –û—Ç–º–µ—á–∞–µ–º –∫–∞–∫ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π
                self.processed_files.add(input_file)
                # –ü—Ä–æ–≥—Ä–µ—Å—Å –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
                
                self.processed_count += 1
                return True
            else:
                logger.warning(f"‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å: {filename}")
                return False
                
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–∞–π–ª–∞ {input_file}: {e}")
            return False

    async def process_directory_async(self, input_dir: str, output_dir: str) -> None:
        """
        –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Å–µ—Ö —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Ñ–∞–π–ª–æ–≤ –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö
        
        Args:
            input_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å –≤—Ö–æ–¥–Ω—ã–º–∏ —Ñ–∞–π–ª–∞–º–∏
            output_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        """
        try:
            logger.info(f"üöÄ –ù–∞—á–∏–Ω–∞–µ–º –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏: {input_dir}")
            
            # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Ñ–∞–π–ª–æ–≤
            logger.info(f"üîç –ü–æ–∏—Å–∫ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Ñ–∞–π–ª–æ–≤...")
            text_files = list(Path(input_dir).glob("*.txt"))
            
            if not text_files:
                logger.warning(f"‚ö†Ô∏è  –í –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ {input_dir} –Ω–µ –Ω–∞–π–¥–µ–Ω–æ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Ñ–∞–π–ª–æ–≤")
                return
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã –≤ –≤—ã—Ö–æ–¥–Ω–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
            processed_files = set()
            if os.path.exists(output_dir):
                processed_files = {f for f in os.listdir(output_dir) if f.lower().endswith('_analyzed.json')}
                processed_files = {f.replace('_analyzed.json', '') for f in processed_files}
            
            logger.info(f"üìÅ –ù–∞–π–¥–µ–Ω–æ {len(text_files)} —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Ñ–∞–π–ª–æ–≤")
            logger.info(f"üìä –£–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {len(processed_files)} —Ñ–∞–π–ª–æ–≤")
            
            # –§–∏–ª—å—Ç—Ä—É–µ–º —Ñ–∞–π–ª—ã –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
            files_to_process = []
            skipped_files = []
            
            for text_file in text_files:
                file_name = text_file.stem  # –ò–º—è —Ñ–∞–π–ª–∞ –±–µ–∑ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è
                output_file = os.path.join(output_dir, f"{file_name}_analyzed.json")
                
                if file_name in processed_files or os.path.exists(output_file):
                    skipped_files.append(str(text_file))
                else:
                    files_to_process.append(str(text_file))
            
            logger.info(f"üìä –ü—Ä–æ–ø—É—â–µ–Ω–æ (—É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ): {len(skipped_files)} —Ñ–∞–π–ª–æ–≤")
            logger.info(f"üìä –ë—É–¥–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {len(files_to_process)} —Ñ–∞–π–ª–æ–≤")
            logger.info(f"üéØ –ë—É–¥–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ –º–∞–∫—Å–∏–º—É–º {self.max_documents} —Ñ–∞–π–ª–æ–≤")
            
            # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∞–π–ª–æ–≤
            files_to_process = files_to_process[:self.max_documents]
            
            if not files_to_process:
                logger.info("‚úÖ –í—Å–µ —Ñ–∞–π–ª—ã —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã!")
                return
            
            logger.info(f"üöÄ –ù–∞—á–∏–Ω–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É {len(files_to_process)} —Ñ–∞–π–ª–æ–≤...")
            
            # –°–æ–∑–¥–∞–µ–º —Å–µ–º–∞—Ñ–æ—Ä –¥–ª—è –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
            semaphore = asyncio.Semaphore(self.max_concurrent)
            
            # –°–æ–∑–¥–∞–µ–º –æ–¥–Ω—É –æ–±—â—É—é —Å–µ—Å—Å–∏—é –¥–ª—è –≤—Å–µ—Ö –∑–∞–¥–∞—á —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –ø—Ä–æ–∫—Å–∏
            connector = aiohttp.TCPConnector(limit=self.max_concurrent * 2)
            timeout = aiohttp.ClientTimeout(total=120)
            
            # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ø—Ä–æ–∫—Å–∏ (–µ—Å–ª–∏ VPN –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –ª–æ–∫–∞–ª—å–Ω—ã–π –ø—Ä–æ–∫—Å–∏)
            proxy_settings = None
            # –ü–æ–ø—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –ø—Ä–æ–∫—Å–∏ –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
            if os.getenv('HTTP_PROXY'):
                proxy_settings = os.getenv('HTTP_PROXY')
            elif os.getenv('HTTPS_PROXY'):
                proxy_settings = os.getenv('HTTPS_PROXY')
            # –û–±—ã—á–Ω—ã–µ –ø–æ—Ä—Ç—ã VPN –ø—Ä–æ–∫—Å–∏
            elif not proxy_settings:
                # –ü–æ–ø—Ä–æ–±—É–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –ø–æ—Ä—Ç—ã VPN
                for port in [12334, 1080, 8080, 3128, 8888]:
                    proxy_settings = f"http://127.0.0.1:{port}"
                    break  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–≤—ã–π –¥–æ—Å—Ç—É–ø–Ω—ã–π
            
            if proxy_settings:
                logger.info(f"üîó –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ–∫—Å–∏: {proxy_settings}")
            
            async with aiohttp.ClientSession(
                connector=connector, 
                timeout=timeout,
                connector_owner=False
            ) as session:
                async def process_with_semaphore(file_path):
                    async with semaphore:
                        return await self.process_text_file_async(session, file_path, output_dir, proxy_settings)
                
                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ñ–∞–π–ª—ã –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ
                tasks = [process_with_semaphore(file_path) for file_path in files_to_process]
                
                # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä
                with tqdm(total=len(tasks), desc="üìÑ –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞", unit="–¥–æ–∫") as pbar:
                    completed = 0
                    for coro in asyncio.as_completed(tasks):
                        result = await coro
                        completed += 1
                        pbar.update(1)
                        
                        if result:
                            logger.info(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {completed}/{len(tasks)}")
                        else:
                            logger.warning(f"‚ö†Ô∏è  –ü—Ä–æ–ø—É—â–µ–Ω –¥–æ–∫—É–º–µ–Ω—Ç")
                
                logger.info(f"\nüéâ –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
                logger.info(f"üìä –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
                logger.info(f"   ‚úÖ –£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {self.processed_count} —Ñ–∞–π–ª–æ–≤")
                logger.info(f"   üìÅ –í—Å–µ–≥–æ –Ω–∞–π–¥–µ–Ω–æ: {len(text_files)} —Ñ–∞–π–ª–æ–≤")
                logger.info(f"   üéØ –õ–∏–º–∏—Ç: {self.max_documents} —Ñ–∞–π–ª–æ–≤")
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ {input_dir}: {e}")

async def main():
    parser = argparse.ArgumentParser(description='–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å—É–¥–µ–±–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —Å –ø–æ–º–æ—â—å—é OpenAI API')
    parser.add_argument('--input-dir', type=str, required=True, help='–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å —Ç–µ–∫—Å—Ç–æ–≤—ã–º–∏ —Ñ–∞–π–ª–∞–º–∏')
    parser.add_argument('--output-dir', type=str, required=True, help='–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤')
    parser.add_argument('--api-key', type=str, help='OpenAI API –∫–ª—é—á (–∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –æ–∫—Ä—É–∂–µ–Ω–∏—è OPENAI_API_KEY)')
    parser.add_argument('--model', type=str, default='gpt-4o-mini', help='–ú–æ–¥–µ–ª—å OpenAI –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è')
    parser.add_argument('--max-docs', type=int, default=50000, help='–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏')
    parser.add_argument('--max-concurrent', type=int, default=5, help='–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤')
    
    args = parser.parse_args()
    
    logger.info("="*80)
    logger.info("ü§ñ –ó–ê–ü–£–°–ö –ê–°–ò–ù–•–†–û–ù–ù–û–ì–û –ê–ù–ê–õ–ò–ó–ê –°–£–î–ï–ë–ù–´–• –î–û–ö–£–ú–ï–ù–¢–û–í –° OPENAI")
    logger.info("="*80)
    logger.info(f"üìÅ –í—Ö–æ–¥–Ω–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {args.input_dir}")
    logger.info(f"üìÅ –í—ã—Ö–æ–¥–Ω–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {args.output_dir}")
    logger.info(f"ü§ñ –ú–æ–¥–µ–ª—å OpenAI: {args.model}")
    logger.info(f"üéØ –ú–∞–∫—Å–∏–º—É–º –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {args.max_docs}")
    logger.info(f"‚ö° –ú–∞–∫—Å–∏–º—É–º –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤: {args.max_concurrent}")
    logger.info("="*80)
    
    # –ü–æ–ª—É—á–∞–µ–º API –∫–ª—é—á
    logger.info("üîë –ü—Ä–æ–≤–µ—Ä–∫–∞ OpenAI API –∫–ª—é—á–∞...")
    api_key = args.api_key or os.getenv("OPENAI_API_KEY")
    if not api_key:
        logger.error("‚ùå –ù–µ —É–∫–∞–∑–∞–Ω OpenAI API –∫–ª—é—á. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ --api-key –∏–ª–∏ –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –æ–∫—Ä—É–∂–µ–Ω–∏—è OPENAI_API_KEY")
        return
    
    logger.info("‚úÖ OpenAI API –∫–ª—é—á –Ω–∞–π–¥–µ–Ω")
    
    # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä
    logger.info("üîß –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–≥–æ –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤...")
    processor = AsyncLegalDocumentProcessor(api_key, args.model, args.max_concurrent)
    processor.max_documents = args.max_docs
    logger.info("‚úÖ –ü—Ä–æ—Ü–µ—Å—Å–æ—Ä –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
    
    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã
    logger.info("üöÄ –ù–∞—á–∏–Ω–∞–µ–º –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤...")
    start_time = time.time()
    
    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã
    await processor.process_directory_async(args.input_dir, args.output_dir)
    
    total_time = time.time() - start_time
    
    logger.info("="*80)
    logger.info("üéâ –ê–°–ò–ù–•–†–û–ù–ù–ê–Ø –û–ë–†–ê–ë–û–¢–ö–ê –ó–ê–í–ï–†–®–ï–ù–ê!")
    logger.info("="*80)
    logger.info(f"‚è±Ô∏è  –û–±—â–µ–µ –≤—Ä–µ–º—è: {total_time:.2f} —Å–µ–∫—É–Ω–¥ ({total_time/60:.1f} –º–∏–Ω—É—Ç)")
    logger.info(f"üìä –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {processor.processed_count}")
    logger.info(f"üöÄ –°—Ä–µ–¥–Ω—è—è —Å–∫–æ—Ä–æ—Å—Ç—å: {processor.processed_count/(total_time/60):.1f} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤/–º–∏–Ω—É—Ç—É")
    logger.info("="*80)

if __name__ == "__main__":
    asyncio.run(main())