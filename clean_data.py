#!/usr/bin/env python
# -*- coding: utf-8 -*-

import os
import shutil
import argparse
from pathlib import Path
from loguru import logger

def clean_directory(directory_path, description):
    """
    –û—á–∏—Å—Ç–∫–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —Å –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ–º
    
    Args:
        directory_path: –ü—É—Ç—å –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
        description: –û–ø–∏—Å–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –¥–ª—è –ª–æ–≥–æ–≤
    """
    if os.path.exists(directory_path):
        try:
            # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∞–π–ª–æ–≤ –ø–µ—Ä–µ–¥ —É–¥–∞–ª–µ–Ω–∏–µ–º
            file_count = len(list(Path(directory_path).rglob('*')))
            
            # –£–¥–∞–ª—è–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é
            shutil.rmtree(directory_path)
            logger.success(f"‚úÖ {description}: —É–¥–∞–ª–µ–Ω–æ {file_count} —Ñ–∞–π–ª–æ–≤/–ø–∞–ø–æ–∫")
            return True
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—á–∏—Å—Ç–∫–µ {description}: {e}")
            return False
    else:
        logger.info(f"‚ÑπÔ∏è {description}: –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")
        return True

def clean_file(file_path, description):
    """
    –£–¥–∞–ª–µ–Ω–∏–µ —Ñ–∞–π–ª–∞ —Å –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ–º
    
    Args:
        file_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É
        description: –û–ø–∏—Å–∞–Ω–∏–µ —Ñ–∞–π–ª–∞ –¥–ª—è –ª–æ–≥–æ–≤
    """
    if os.path.exists(file_path):
        try:
            os.remove(file_path)
            logger.success(f"‚úÖ {description}: —Ñ–∞–π–ª —É–¥–∞–ª–µ–Ω")
            return True
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏ {description}: {e}")
            return False
    else:
        logger.info(f"‚ÑπÔ∏è {description}: —Ñ–∞–π–ª –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")
        return True

def clean_processed_data():
    """–û—á–∏—Å—Ç–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
    logger.info("üßπ –û—á–∏—Å—Ç–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö...")
    
    items_to_clean = [
        ("data/structured", "–°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ"),
        ("data/analyzed", "–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ JSON —Ñ–∞–π–ª—ã"),
        ("data/train_dataset.jsonl", "–û–±—É—á–∞—é—â–∏–π –¥–∞—Ç–∞—Å–µ—Ç"),
        ("data/train_dataset_test.jsonl", "–¢–µ—Å—Ç–æ–≤—ã–π –¥–∞—Ç–∞—Å–µ—Ç"),
        ("data/train_dataset_meta.json", "–ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –¥–∞—Ç–∞—Å–µ—Ç–∞"),
    ]
    
    success_count = 0
    for path, description in items_to_clean:
        if path.endswith('.jsonl') or path.endswith('.json'):
            if clean_file(path, description):
                success_count += 1
        else:
            if clean_directory(path, description):
                success_count += 1
    
    return success_count == len(items_to_clean)

def clean_model_data():
    """–û—á–∏—Å—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–∏"""
    logger.info("üßπ –û—á–∏—Å—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–∏...")
    
    items_to_clean = [
        ("models/legal_model", "–û–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å"),
        ("models/legal_model/logs", "–õ–æ–≥–∏ –æ–±—É—á–µ–Ω–∏—è"),
    ]
    
    success_count = 0
    for path, description in items_to_clean:
        if clean_directory(path, description):
            success_count += 1
    
    return success_count == len(items_to_clean)

def clean_results():
    """–û—á–∏—Å—Ç–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""
    logger.info("üßπ –û—á–∏—Å—Ç–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤...")
    
    items_to_clean = [
        ("results", "–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"),
    ]
    
    success_count = 0
    for path, description in items_to_clean:
        if clean_directory(path, description):
            success_count += 1
    
    return success_count == len(items_to_clean)

def clean_all():
    """–û—á–∏—Å—Ç–∫–∞ –≤—Å–µ—Ö –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
    logger.info("üßπ –û—á–∏—Å—Ç–∫–∞ –≤—Å–µ—Ö –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö...")
    
    results = []
    results.append(("–û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ", clean_processed_data()))
    results.append(("–î–∞–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏", clean_model_data()))
    results.append(("–†–µ–∑—É–ª—å—Ç–∞—Ç—ã", clean_results()))
    
    success_count = sum(1 for _, success in results if success)
    total_count = len(results)
    
    logger.info(f"\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç –æ—á–∏—Å—Ç–∫–∏: {success_count}/{total_count} —É—Å–ø–µ—à–Ω–æ")
    
    for description, success in results:
        if success:
            logger.success(f"‚úÖ {description}: –æ—á–∏—â–µ–Ω–æ")
        else:
            logger.error(f"‚ùå {description}: –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ—á–∏—Å—Ç–∫–µ")
    
    return success_count == total_count

def show_status():
    """–ü–æ–∫–∞–∑–∞—Ç—å —Å—Ç–∞—Ç—É—Å –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π"""
    logger.info("üìä –°—Ç–∞—Ç—É—Å –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π –ø—Ä–æ–µ–∫—Ç–∞")
    logger.info("=" * 50)
    
    directories = [
        ("data/raw", "–ò—Å—Ö–æ–¥–Ω—ã–µ PDF —Ñ–∞–π–ª—ã"),
        ("data/processed", "–û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ —Ñ–∞–π–ª—ã"),
        ("data/structured", "–°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ"),
        ("data/analyzed", "–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ JSON —Ñ–∞–π–ª—ã"),
        ("models/legal_model", "–û–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å"),
        ("results", "–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"),
    ]
    
    files = [
        ("data/train_dataset.jsonl", "–û–±—É—á–∞—é—â–∏–π –¥–∞—Ç–∞—Å–µ—Ç"),
        ("data/train_dataset_test.jsonl", "–¢–µ—Å—Ç–æ–≤—ã–π –¥–∞—Ç–∞—Å–µ—Ç"),
        ("data/train_dataset_meta.json", "–ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –¥–∞—Ç–∞—Å–µ—Ç–∞"),
    ]
    
    for path, description in directories:
        if os.path.exists(path):
            file_count = len(list(Path(path).rglob('*')))
            logger.info(f"üìÅ {description}: {file_count} —Ñ–∞–π–ª–æ–≤/–ø–∞–ø–æ–∫")
        else:
            logger.info(f"üìÅ {description}: –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")
    
    for path, description in files:
        if os.path.exists(path):
            size = os.path.getsize(path) / 1024  # KB
            logger.info(f"üìÑ {description}: {size:.1f} KB")
        else:
            logger.info(f"üìÑ {description}: –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")

def main():
    parser = argparse.ArgumentParser(description='–û—á–∏—Å—Ç–∫–∞ –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –ø—Ä–æ–µ–∫—Ç–∞')
    parser.add_argument('--processed', action='store_true', help='–û—á–∏—Å—Ç–∏—Ç—å –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ')
    parser.add_argument('--model', action='store_true', help='–û—á–∏—Å—Ç–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏')
    parser.add_argument('--results', action='store_true', help='–û—á–∏—Å—Ç–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã')
    parser.add_argument('--all', action='store_true', help='–û—á–∏—Å—Ç–∏—Ç—å –≤—Å–µ –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ')
    parser.add_argument('--status', action='store_true', help='–ü–æ–∫–∞–∑–∞—Ç—å —Å—Ç–∞—Ç—É—Å –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π')
    parser.add_argument('--force', action='store_true', help='–ù–µ –∑–∞–ø—Ä–∞—à–∏–≤–∞—Ç—å –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ')
    
    args = parser.parse_args()
    
    # –ï—Å–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω—ã –∞—Ä–≥—É–º–µ–Ω—Ç—ã, –ø–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç–∞—Ç—É—Å
    if not any([args.processed, args.model, args.results, args.all, args.status]):
        show_status()
        return
    
    if args.status:
        show_status()
        return
    
    # –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ –æ —É–¥–∞–ª–µ–Ω–∏–∏
    if not args.force:
        logger.warning("‚ö†Ô∏è –í–ù–ò–ú–ê–ù–ò–ï: –≠—Ç–æ –¥–µ–π—Å—Ç–≤–∏–µ —É–¥–∞–ª–∏—Ç –¥–∞–Ω–Ω—ã–µ –±–µ–∑–≤–æ–∑–≤—Ä–∞—Ç–Ω–æ!")
        logger.warning("–ò—Å—Ö–æ–¥–Ω—ã–µ PDF —Ñ–∞–π–ª—ã –≤ data/raw/ –ù–ï –±—É–¥—É—Ç –∑–∞—Ç—Ä–æ–Ω—É—Ç—ã.")
        
        if args.all:
            logger.warning("–ë—É–¥—É—Ç —É–¥–∞–ª–µ–Ω—ã: –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ, –º–æ–¥–µ–ª—å, —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã")
        elif args.processed:
            logger.warning("–ë—É–¥—É—Ç —É–¥–∞–ª–µ–Ω—ã: —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ")
        elif args.model:
            logger.warning("–ë—É–¥—É—Ç —É–¥–∞–ª–µ–Ω—ã: –º–æ–¥–µ–ª—å –∏ –ª–æ–≥–∏ –æ–±—É—á–µ–Ω–∏—è")
        elif args.results:
            logger.warning("–ë—É–¥—É—Ç —É–¥–∞–ª–µ–Ω—ã: —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è")
        
        response = input("\n–ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å? (y/N): ").strip().lower()
        if response not in ['y', 'yes', '–¥–∞']:
            logger.info("‚ùå –û–ø–µ—Ä–∞—Ü–∏—è –æ—Ç–º–µ–Ω–µ–Ω–∞")
            return
    
    logger.info("üöÄ –ù–∞—á–∞–ª–æ –æ—á–∏—Å—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö")
    logger.info("=" * 50)
    
    success = False
    if args.all:
        success = clean_all()
    elif args.processed:
        success = clean_processed_data()
    elif args.model:
        success = clean_model_data()
    elif args.results:
        success = clean_results()
    
    logger.info("=" * 50)
    if success:
        logger.success("üéâ –û—á–∏—Å—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ!")
        logger.info("–¢–µ–ø–µ—Ä—å –º–æ–∂–Ω–æ –∑–∞–ø—É—Å—Ç–∏—Ç—å –ø–∞–π–ø–ª–∞–π–Ω –∑–∞–Ω–æ–≤–æ:")
        logger.info("python run_pipeline.py --max-docs 3 --epochs 3")
    else:
        logger.error("üí• –û—á–∏—Å—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —Å –æ—à–∏–±–∫–∞–º–∏")

if __name__ == '__main__':
    main()