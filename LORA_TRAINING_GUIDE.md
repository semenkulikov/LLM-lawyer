# üöÄ –†—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –ø–æ –æ–±—É—á–µ–Ω–∏—é –º–æ–¥–µ–ª–∏ —Å LoRA

## üìã –û–±–∑–æ—Ä

–≠—Ç–æ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –æ–ø–∏—Å—ã–≤–∞–µ—Ç –ø—Ä–æ—Ü–µ—Å—Å –¥–æ–æ–±—É—á–µ–Ω–∏—è –≤–∞—à–µ–π –ª–æ–∫–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏ QVikhr-3-4B —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –º–µ—Ç–æ–¥–∞ LoRA (Low-Rank Adaptation) –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø–æ–ª–Ω–æ—Ü–µ–Ω–Ω—ã—Ö —é—Ä–∏–¥–∏—á–µ—Å–∫–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤.

## üéØ –ß—Ç–æ –º—ã –¥–µ–ª–∞–µ–º

1. **–°–æ–±–∏—Ä–∞–µ–º –¥–∞–Ω–Ω—ã–µ** - GUI –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –≥–∏–±—Ä–∏–¥–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ –¥–∞—Ç–∞—Å–µ—Ç
2. **–û—á–∏—â–∞–µ–º –¥–∞–Ω–Ω—ã–µ** - —Ñ–∏–ª—å—Ç—Ä—É–µ–º –º—É—Å–æ—Ä –∏ –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º —Ñ–æ—Ä–º–∞—Ç
3. **–û–±—É—á–∞–µ–º —Å LoRA** - –¥–æ–æ–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å –Ω–∞ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–∞—Ö

## üìä –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∞–Ω–Ω—ã—Ö

### –§–æ—Ä–º–∞—Ç JSONL –¥–ª—è –æ–±—É—á–µ–Ω–∏—è:
```json
{
  "instruction": "–°–æ—Å—Ç–∞–≤—å –∏—Å–∫–æ–≤–æ–µ –∑–∞—è–≤–ª–µ–Ω–∏–µ –ø–æ —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏–º –æ–±—Å—Ç–æ—è—Ç–µ–ª—å—Å—Ç–≤–∞–º –¥–µ–ª–∞.",
  "input": "–ò—Å—Ç–µ—Ü –∑–∞–∫–ª—é—á–∏–ª –¥–æ–≥–æ–≤–æ—Ä —Å –æ—Ç–≤–µ—Ç—á–∏–∫–æ–º –Ω–∞ –æ–∫–∞–∑–∞–Ω–∏–µ —É—Å–ª—É–≥...",
  "output": "–í –°–£–î–ï\n\n–ò–°–¢–ï–¶: –ò–≤–∞–Ω–æ–≤ –ò.–ò.\n–û–¢–í–ï–¢–ß–ò–ö: –û–û–û \"–£—Å–ª—É–≥–∏\"\n\n–ò–°–ö–û–í–û–ï –ó–ê–Ø–í–õ–ï–ù–ò–ï\n\n–ú–û–¢–ò–í–ò–†–û–í–û–ß–ù–ê–Ø –ß–ê–°–¢–¨:\n–°–æ–≥–ª–∞—Å–Ω–æ —Å—Ç. 309 –ì–ö –†–§...\n\n–†–ï–ó–û–õ–Æ–¢–ò–í–ù–ê–Ø –ß–ê–°–¢–¨:\n–ü–†–û–®–£ –°–£–î..."
}
```

### –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ):
```json
{
  "metadata": {
    "local_response": "–§–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –æ–±—Å—Ç–æ—è—Ç–µ–ª—å—Å—Ç–≤–∞...",
    "provider": "openai",
    "mode": "polish",
    "timestamp": "2025-08-28T23:14:59.007455",
    "version": "1.0"
  }
}
```

## üîß –ü–æ—à–∞–≥–æ–≤—ã–π –ø—Ä–æ—Ü–µ—Å—Å

### –®–∞–≥ 1: –°–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö —á–µ—Ä–µ–∑ GUI

1. –ó–∞–ø—É—Å—Ç–∏—Ç–µ GUI: `python gui/legal_assistant_gui.py`
2. –í–∫–ª—é—á–∏—Ç–µ "–°–æ—Ö—Ä–∞–Ω—è—Ç—å –≤ –¥–∞—Ç–∞—Å–µ—Ç –¥–ª—è –æ–±—É—á–µ–Ω–∏—è"
3. –ì–µ–Ω–µ—Ä–∏—Ä—É–π—Ç–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã - –æ–Ω–∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–æ—Ö—Ä–∞–Ω—è—Ç—Å—è
4. –°–æ–±–µ—Ä–∏—Ç–µ –º–∏–Ω–∏–º—É–º 1000 –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤

### –®–∞–≥ 2: –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–æ–≤

```bash
python src/merge_datasets.py
```

–°–æ–∑–¥–∞–µ—Ç:
- `datasets/merged_training_dataset.jsonl` - –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç
- `datasets/training_config.json` - –±–∞–∑–æ–≤–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è

### –®–∞–≥ 3: –û—á–∏—Å—Ç–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞

```bash
python src/dataset_cleaner.py
```

–ò–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –±–∞—Ç–Ω–∏–∫:
```bash
scripts/clean_dataset.bat
```

**–ß—Ç–æ –¥–µ–ª–∞–µ—Ç –æ—á–∏—Å—Ç–∫–∞:**
- ‚úÖ –§–∏–ª—å—Ç—Ä—É–µ—Ç –Ω–µ–≤–∞–ª–∏–¥–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã
- ‚úÖ –£–±–∏—Ä–∞–µ—Ç –º—É—Å–æ—Ä –∏ –æ—Ñ—Ñ—Ç–æ–ø
- ‚úÖ –ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É
- ‚úÖ –î–æ–±–∞–≤–ª—è–µ—Ç —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–π
- ‚úÖ –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–∞–ª–∏—á–∏–µ –º–æ—Ç–∏–≤–∏—Ä–æ–≤–æ—á–Ω–æ–π —á–∞—Å—Ç–∏

### –®–∞–≥ 4: –û–±—É—á–µ–Ω–∏–µ —Å LoRA

```bash
python src/train_lora.py --config datasets/lora_training_config.json
```

–ò–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –±–∞—Ç–Ω–∏–∫:
```bash
scripts/train_lora.bat
```

## ‚öôÔ∏è –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è LoRA

### –û–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è RTX 3070 (8GB):

```json
{
  "training_args": {
    "num_train_epochs": 3,
    "per_device_train_batch_size": 1,
    "gradient_accumulation_steps": 8,
    "learning_rate": 1e-4,
    "fp16": true,
    "gradient_checkpointing": true
  },
  "lora_config": {
    "r": 16,
    "lora_alpha": 32,
    "target_modules": ["q_proj", "v_proj", "k_proj", "o_proj"],
    "lora_dropout": 0.05
  }
}
```

### –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è —Ä–∞–∑–Ω—ã—Ö GPU:

| GPU | Batch Size | Gradient Accumulation | Memory Usage |
|-----|------------|----------------------|--------------|
| RTX 3070 (8GB) | 1 | 8 | ~7GB |
| RTX 3080 (10GB) | 2 | 4 | ~9GB |
| RTX 3090 (24GB) | 4 | 2 | ~18GB |

## üìà –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –æ–±—É—á–µ–Ω–∏—è

### –ö–ª—é—á–µ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏:
- **Training Loss** - –¥–æ–ª–∂–µ–Ω —É–º–µ–Ω—å—à–∞—Ç—å—Å—è
- **Eval Loss** - –∫–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É–π—Ç–µ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ
- **Learning Rate** - –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–Ω–∏–∂–∞–µ—Ç—Å—è

### –ü—Ä–∏–∑–Ω–∞–∫–∏ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è:
- Eval Loss —Ä–∞—Å—Ç–µ—Ç, –∞ Training Loss –ø–∞–¥–∞–µ—Ç
- –ú–æ–¥–µ–ª—å –Ω–∞—á–∏–Ω–∞–µ—Ç –ø–æ–≤—Ç–æ—Ä—è—Ç—å —à–∞–±–ª–æ–Ω—ã
- –ö–∞—á–µ—Å—Ç–≤–æ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —É—Ö—É–¥—à–∞–µ—Ç—Å—è

## üéØ –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏

### –†–∞–∑–º–µ—Ä –¥–∞—Ç–∞—Å–µ—Ç–∞:
- **–ú–∏–Ω–∏–º—É–º**: 1000 –ø—Ä–∏–º–µ—Ä–æ–≤
- **–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è**: 3000-5000 –ø—Ä–∏–º–µ—Ä–æ–≤
- **–û–ø—Ç–∏–º–∞–ª—å–Ω–æ**: 10000+ –ø—Ä–∏–º–µ—Ä–æ–≤

### –ö–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö:
- ‚úÖ –¢–æ–ª—å–∫–æ –≤–∞–ª–∏–¥–Ω—ã–µ —é—Ä–∏–¥–∏—á–µ—Å–∫–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã
- ‚úÖ –ï–¥–∏–Ω–æ–æ–±—Ä–∞–∑–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞
- ‚úÖ –†–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏
- ‚ùå –ë–µ–∑ –º—É—Å–æ—Ä–∞ –∏ –æ—Ñ—Ñ—Ç–æ–ø–∞

### –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±—É—á–µ–Ω–∏—è:
- **–≠–ø–æ—Ö–∏**: 3-5 (–±–æ–ª—å—à–µ = —Ä–∏—Å–∫ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è)
- **Learning Rate**: 1e-4 –¥–ª—è LoRA
- **Batch Size**: –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –≤–æ–∑–º–æ–∂–Ω—ã–π –¥–ª—è –≤–∞—à–µ–≥–æ GPU

## üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

–ü–æ—Å–ª–µ –æ–±—É—á–µ–Ω–∏—è –ø—Ä–æ–≤–µ—Ä—å—Ç–µ:

1. **–°—Ç—Ä—É–∫—Ç—É—Ä—É –¥–æ–∫—É–º–µ–Ω—Ç–∞** - –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –ø–æ–ª–Ω–æ–π
2. **–ú–æ—Ç–∏–≤–∏—Ä–æ–≤–æ—á–Ω—É—é —á–∞—Å—Ç—å** - –¥–æ–ª–∂–Ω–∞ —Å–æ–¥–µ—Ä–∂–∞—Ç—å –ø—Ä–∞–≤–æ–≤—ã–µ —Å—Å—ã–ª–∫–∏
3. **–°—Ç–∏–ª—å** - –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω–æ-–¥–µ–ª–æ–≤–æ–π
4. **–õ–æ–≥–∏–∫—É** - –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π

## üìÅ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ñ–∞–π–ª–æ–≤

```
datasets/
‚îú‚îÄ‚îÄ hybrid_generated/           # –°—ã—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ –æ—Ç GUI
‚îÇ   ‚îî‚îÄ‚îÄ dataset_*.jsonl
‚îú‚îÄ‚îÄ merged_training_dataset.jsonl    # –û–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç
‚îú‚îÄ‚îÄ clean_training_dataset.jsonl     # –û—á–∏—â–µ–Ω–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç
‚îú‚îÄ‚îÄ lora_training_config.json        # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è LoRA
‚îî‚îÄ‚îÄ training_config.json             # –ë–∞–∑–æ–≤–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è

models/
‚îî‚îÄ‚îÄ legal_model_lora/          # –û–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å
    ‚îú‚îÄ‚îÄ adapter_config.json
    ‚îú‚îÄ‚îÄ adapter_model.bin
    ‚îî‚îÄ‚îÄ tokenizer.json
```

## üö® –£—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º

### –û—à–∏–±–∫–∞ "CUDA out of memory":
- –£–º–µ–Ω—å—à–∏—Ç–µ `per_device_train_batch_size`
- –£–≤–µ–ª–∏—á—å—Ç–µ `gradient_accumulation_steps`
- –í–∫–ª—é—á–∏—Ç–µ `gradient_checkpointing`

### –ú–µ–¥–ª–µ–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ:
- –£–≤–µ–ª–∏—á—å—Ç–µ `batch_size` –µ—Å–ª–∏ –ø–æ–∑–≤–æ–ª—è–µ—Ç –ø–∞–º—è—Ç—å
- –£–º–µ–Ω—å—à–∏—Ç–µ `max_length` –≤ data_config
- –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ `fp16: true`

### –ü–ª–æ—Ö–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏:
- –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∫–∞—á–µ—Å—Ç–≤–æ –¥–∞—Ç–∞—Å–µ—Ç–∞
- –£–≤–µ–ª–∏—á—å—Ç–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–º–µ—Ä–æ–≤
- –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –±–æ–ª—å—à–µ —ç–ø–æ—Ö (–Ω–æ —Å–ª–µ–¥–∏—Ç–µ –∑–∞ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ–º)

## üéâ –†–µ–∑—É–ª—å—Ç–∞—Ç

–ü–æ—Å–ª–µ —É—Å–ø–µ—à–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –≤—ã –ø–æ–ª—É—á–∏—Ç–µ –º–æ–¥–µ–ª—å, –∫–æ—Ç–æ—Ä–∞—è:

- ‚úÖ –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –ø–æ–ª–Ω–æ—Ü–µ–Ω–Ω—ã–µ —é—Ä–∏–¥–∏—á–µ—Å–∫–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã
- ‚úÖ –°–æ–¥–µ—Ä–∂–∏—Ç –º–æ—Ç–∏–≤–∏—Ä–æ–≤–æ—á–Ω—É—é —á–∞—Å—Ç—å —Å –ø—Ä–∞–≤–æ–≤—ã–º–∏ —Å—Å—ã–ª–∫–∞–º–∏
- ‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω–æ-–¥–µ–ª–æ–≤–æ–π —Å—Ç–∏–ª—å
- ‚úÖ –†–∞–±–æ—Ç–∞–µ—Ç –±–µ–∑ –≤–Ω–µ—à–Ω–∏—Ö LLM (—Ç–æ–ª—å–∫–æ –ª–æ–∫–∞–ª—å–Ω–æ)

## üìû –ü–æ–¥–¥–µ—Ä–∂–∫–∞

–ü—Ä–∏ –≤–æ–∑–Ω–∏–∫–Ω–æ–≤–µ–Ω–∏–∏ –ø—Ä–æ–±–ª–µ–º:
1. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ª–æ–≥–∏ –≤ –∫–æ–Ω—Å–æ–ª–∏
2. –£–±–µ–¥–∏—Ç–µ—Å—å –≤ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ—Å—Ç–∏ –¥–∞–Ω–Ω—ã—Ö
3. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é GPU
4. –û–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∫ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ Hugging Face
