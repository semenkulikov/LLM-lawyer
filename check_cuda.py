#!/usr/bin/env python
# -*- coding: utf-8 -*-

import torch
import sys
from loguru import logger

def check_cuda():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ CUDA"""
    logger.info("üîç –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ CUDA")
    logger.info("=" * 50)
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ PyTorch
    try:
        import torch
        logger.info(f"PyTorch –≤–µ—Ä—Å–∏—è: {torch.__version__}")
    except ImportError:
        logger.error("PyTorch –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
        return False
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ CUDA
    cuda_available = torch.cuda.is_available()
    logger.info(f"CUDA –¥–æ—Å—Ç—É–ø–Ω–∞: {cuda_available}")
    
    if cuda_available:
        logger.success("‚úÖ CUDA —Ä–∞–±–æ—Ç–∞–µ—Ç!")
        logger.info(f"CUDA –≤–µ—Ä—Å–∏—è: {torch.version.cuda}")
        logger.info(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ GPU: {torch.cuda.device_count()}")
        
        for i in range(torch.cuda.device_count()):
            gpu_name = torch.cuda.get_device_name(i)
            gpu_memory = torch.cuda.get_device_properties(i).total_memory / 1024**3
            logger.info(f"GPU {i}: {gpu_name} ({gpu_memory:.1f} GB)")
        
        # –¢–µ—Å—Ç CUDA
        try:
            x = torch.randn(1000, 1000).cuda()
            y = torch.randn(1000, 1000).cuda()
            z = torch.mm(x, y)
            logger.success("‚úÖ CUDA —Ç–µ—Å—Ç –ø—Ä–æ–π–¥–µ–Ω —É—Å–ø–µ—à–Ω–æ!")
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ CUDA —Ç–µ—Å—Ç–∞: {e}")
            return False
    else:
        logger.error("‚ùå CUDA –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞!")
        logger.info("–í–æ–∑–º–æ–∂–Ω—ã–µ –ø—Ä–∏—á–∏–Ω—ã:")
        logger.info("1. –ù–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω CUDA toolkit")
        logger.info("2. PyTorch —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –±–µ–∑ –ø–æ–¥–¥–µ—Ä–∂–∫–∏ CUDA")
        logger.info("3. –ù–µ—Ç —Å–æ–≤–º–µ—Å—Ç–∏–º–æ–π –≤–∏–¥–µ–æ–∫–∞—Ä—Ç—ã NVIDIA")
        logger.info("4. –î—Ä–∞–π–≤–µ—Ä—ã NVIDIA –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —É—Å—Ç–∞–Ω–æ–≤–∫–∏ PyTorch
        logger.info("\n–ü—Ä–æ–≤–µ—Ä–∫–∞ —É—Å—Ç–∞–Ω–æ–≤–∫–∏ PyTorch:")
        try:
            import torch
            logger.info(f"PyTorch —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω: {torch.__version__}")
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞, –µ—Å—Ç—å –ª–∏ CUDA –≤ PyTorch
            if hasattr(torch, 'cuda'):
                logger.info("PyTorch –∏–º–µ–µ—Ç –º–æ–¥—É–ª—å CUDA")
            else:
                logger.error("PyTorch –Ω–µ –∏–º–µ–µ—Ç –º–æ–¥—É–ª—è CUDA")
                
        except ImportError:
            logger.error("PyTorch –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
            return False
    
    return cuda_available

def check_system():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–∏—Å—Ç–µ–º—ã"""
    logger.info("\nüîß –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å–∏—Å—Ç–µ–º–µ")
    logger.info("=" * 50)
    
    import platform
    logger.info(f"–û–°: {platform.system()} {platform.release()}")
    logger.info(f"–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞: {platform.machine()}")
    logger.info(f"Python: {sys.version}")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
    import os
    cuda_home = os.environ.get('CUDA_HOME')
    cuda_path = os.environ.get('CUDA_PATH')
    
    if cuda_home:
        logger.info(f"CUDA_HOME: {cuda_home}")
    else:
        logger.warning("CUDA_HOME –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞")
    
    if cuda_path:
        logger.info(f"CUDA_PATH: {cuda_path}")
    else:
        logger.warning("CUDA_PATH –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞")

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    logger.info("üöÄ –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ —Å–∏—Å—Ç–µ–º—ã –¥–ª—è PyTorch + CUDA")
    logger.info("=" * 60)
    
    check_system()
    cuda_works = check_cuda()
    
    logger.info("\n" + "=" * 60)
    if cuda_works:
        logger.success("üéâ CUDA —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ! –ú–æ–¥–µ–ª—å –±—É–¥–µ—Ç –æ–±—É—á–∞—Ç—å—Å—è –Ω–∞ GPU.")
        logger.info("–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:")
        logger.info("- –£–≤–µ–ª–∏—á—å—Ç–µ batch_size –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è –æ–±—É—á–µ–Ω–∏—è")
        logger.info("- –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ fp16=True –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –ø–∞–º—è—Ç–∏")
    else:
        logger.warning("‚ö†Ô∏è CUDA –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞. –ú–æ–¥–µ–ª—å –±—É–¥–µ—Ç –æ–±—É—á–∞—Ç—å—Å—è –Ω–∞ CPU.")
        logger.info("–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:")
        logger.info("- –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ CUDA toolkit –∏ PyTorch —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π CUDA")
        logger.info("- –£–º–µ–Ω—å—à–∏—Ç–µ batch_size –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –ø–∞–º—è—Ç–∏ CPU")
        logger.info("- –û–±—É—á–µ–Ω–∏–µ –±—É–¥–µ—Ç –º–µ–¥–ª–µ–Ω–Ω–µ–µ, –Ω–æ –≤—Å–µ —Ä–∞–≤–Ω–æ –≤–æ–∑–º–æ–∂–Ω–æ")

if __name__ == '__main__':
    main() 